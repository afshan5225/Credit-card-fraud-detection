# -*- coding: utf-8 -*-
"""Credit Card Fraud  detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y2zfI-6J3rBhDhq8_s3rzF8W_-SKCdcG

#**Credit Card Fraud detection**

import libraries
"""

import pandas as pd
 import numpy as np
 import matplotlib.pyplot as plt
 import seaborn as sns
 from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier
 from sklearn.tree import DecisionTreeClassifier
 from sklearn.metrics import confusion_matrix,accuracy_score
 from sklearn.model_selection import KFold,StratifiedKFold,RandomizedSearchCV
 import re
 from sklearn.preprocessing import StandardScaler

"""Import dataset"""

df = pd.read_csv("/content/drive/MyDrive/dataset/creditcard.csv")

df.head()

"""#Data analysis"""

df.shape

df.info()

df.isna().sum()

df.describe()

df.columns

df['Class'].value_counts()

#plt.figure(figsize=(150,150))
#sns.heatmap(data = df.corr(),annot = True)

"""Feature selection and importance"""

X = df.iloc[:,:-1]

y= df.iloc[:,-1]

X.columns

model =ExtraTreesClassifier()

model.fit(X,y)

model.feature_importances_

modimp = pd.Series(model.feature_importances_, index = X.columns)
modimp.nlargest(20).plot(kind = 'bar')

X_new = modimp.nlargest(18)

cols  = X_new.index

X_new = X[cols]

X_new

"""spliting the data"""

stf = StratifiedKFold(n_splits = 10 )

for train_index,test_index in stf.split(X,y):
  X_train,X_test = X.iloc[train_index],X.iloc[test_index]
  y_train,y_test =y.iloc[train_index],y.iloc[test_index]

for train_index,test_index in stf.split(X_new,y):
  X_new_train,X_new_test = X.iloc[train_index],X.iloc[test_index]
  y_new_train,y_new_test =y.iloc[train_index],y.iloc[test_index]

"""# Model selection"""

decison = DecisionTreeClassifier()
randf = RandomForestClassifier()

"""# Hyperparameter tuning for randomforest classifier"""

n_estimators = [int(i) for i in np.linspace(100,2000,12)] #100,2000, 20 rounds
max_features = ['auto','sqrt', 'log2']
max_depth = [int(i) for i in np.linspace(5,30,5)]
min_samples_split = [2,5,10,15,100]
min_samples_leaf = [1,2,5,10]

'''#param = {
    'n_estimators': n_estimators,
    'max_features':max_features,
    'max_depth': max_depth,
    'min_samples_split': min_samples_split,
    'min_samples_leaf': min_samples_leaf




}#'''

#rf_model = RandomizedSearchCV( estimator = randf, param_distributions = param,scoring = 'neg_mean_squared_error',n_jobs =1,cv =5,verbose =2 ,random_state =42)

#rf_model.fit(X_train,y_train)

"""Auto ML using Lazy predict"""

#!pip install LazyPredict

#from lazypredict.Supervised import LazyClassifier

'''
clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)
models,predictions = clf.fit(X_train, X_test, y_train, y_test)
'''

#print(models)

"""checking accuracy of randomf"""

randf.fit(X_train,y_train)

y_pred = randf.predict(X_test)

accuracy_score(y_pred,y_test)